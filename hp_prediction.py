# -*- coding: utf-8 -*-
"""Hp_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1elGT9zpenAgGpcxZ-T1VsfCjXygeEPEo
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error

#importing data set
data = pd.read_csv(r'/content/Housing.csv')

#Data explotary and cleaning
#Manual checking
print(data.head(),"\n")#which prints 1st 5 records in the data set
print(data.tail(),"\n")#last 5 records

#understanding our data
print("No of rows and columns in dataset",data.shape,"\n")
print("\nDataset info")
print(data.info())

#checking our data is there any missing values
print("\n Missing values checking:\n",data.isnull().sum())#if null value is present,sum it and display
print("\n There is no missing values in dataset")

#Feature selection
#preprocess data
print("\n Categorical columns")
categorical_col =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']#colums have yes or no values
print(data[categorical_col])

#binary encoding process converting categorical value(y/n) values into numerical value(1/0)
#we do this process because ml algo requires numerical input
def binary_map(x):
    return x.map({'yes':1,'no':0})
data[categorical_col]=data[categorical_col].apply(binary_map)
print("\n After binary encode process\n")
print(data[categorical_col])

#handle categorical variable(furnishingstatus) with dummy variable
print("\nDummy variable process")
dum_col=pd.get_dummies(data['furnishingstatus'])
print(dum_col)

dum_col=pd.get_dummies(data['furnishingstatus'],drop_first=True)#drop the 1st column
print("\n Dropped furnished column from dummy_columns")
print(dum_col)

#binary encoding process
print("\nConverted categorical values(T,F) of semifurnished & unfurnished columns into 0 and 1")

def dm(x):
    return x.map({True:1,False:0})
dum=dum_col.apply(dm)#converting process
print(dum)

#add the new columns (semifurnished,unfurnished) to dataset
data = pd.concat([data, dum], axis=1)#cocat semifunished,unfurnished columns to dataset
print("\nAdded the semifunished,unfurnished columns to dataset")
data.drop(['furnishingstatus'], axis=1, inplace=True)
print("\nDropped furnishingstatus column from dataset\n")

print("\nUpdated Dataset\n",data.head())

#splitting data into training and testing phases
np.random.seed(0)#random genrating numbers starts from 0
df_train, df_test = train_test_split(data, train_size=0.7, test_size=0.3, random_state=100)
print("No of records in train set",df_train.shape)#display how many records are used for training
print("No of recors in test set",df_test.shape)

#Model training
scalar=MinMaxScaler()
#columns to scale
col_to_scale = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'price']
df_train[col_to_scale]=scalar.fit_transform(df_train[col_to_scale])#scale train data
x_train=df_train
y_train=df_train.pop('price')
lr=LinearRegression()
lr.fit(x_train,y_train)

#Model testing
col_to_scale = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']
df_test[col_to_scale] = scalar.fit_transform(df_test[col_to_scale])#scale test data

#prediction
y_test = df_test.pop('price')
x_test = df_test
predict=lr.predict(x_test)

#r2 defines goodness of fit
r2 = r2_score(y_test, predict)
print("R2 score",r2)#higher r2 score means it good model
mse = mean_squared_error(y_test, predict)#mse = diff b/w acutal and predict values
print("Mean Squared Error:", mse)#lower mse means it good model

#comparing actual and predicted values
data_frame = pd.DataFrame({'Actual': y_test, 'Predicted': predict})
print(data_frame)

#visualization
fig = plt.figure()
plt.scatter(y_test, predict)
plt.title('Actual vs Prediction')
plt.xlabel('Actual', fontsize=15)
plt.ylabel('Predicted', fontsize=15)
plt.show()